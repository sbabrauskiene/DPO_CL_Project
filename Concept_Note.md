# DPO_CL_Project
This repository contains code and supporting material for my CL project involving corpora cleansing and preparation for MT training. 
</br></br>
<i>Ключевые слова: xml parsing, data cleansing, de-duplicaiton, custom stop lists</i>
</br>
# Резюме
С появлением на рынке коммерческих вариантов API для нейронного машинного перевода (МП) и их широким распространением все больше поставщиков услуг перевода и клиентов заинтересованы в применении технологий МП для решения стоящих перед ними задач перевода. МП высоко зарекомендовал себя во множестве областей, позволяя автоматизировать и существенно ускорить перевод контента, объемы которого растут экспоненциально. Зачастую моделей общей тематики (универсальных моделей) недостаточно для качественного перевода сложных текстов, кроме того, у отдельных клиентов могут существовать особые требования с точки зрения терминологии и стиля.</br>

<b>Повышение качества МП в отдельных тематиках за счет тренировки специализированных (кастомных) моделей на параллельных корпусах высокого качества является интересным и востребованным направлением.</b>

</br></br>
Высокое качество тренировочных данных (параллельного корпуса) выступает одним из ключевых факторов эффекивности модели машинного перевода. Прежде чем использовать параллельный корпус для тренировки модели, необходимы действия по его подготовке, очистке и валидации. На этапе очистки данных решается множество проблем, потенциально влияющих на итоговую эффективность модели. Ниже приведены некоторые из действий по очистке данных:</br>
<ol>
    <li>    <b>Удаление дубликатов.</b> Дубликаты являются балластом и бесполезно увеличивают объем корпуса. Под дубликатами обычно понимаются &laquo;полные дубликаты&raquo;, однако в некоторых ситуациях может понадобиться поиск неполных дубликатов. Именно эта задача является основной на первом этапе проекта.</li>
    <li>    <b>Устранение ошибок ввода.</b> При создании корпусов вручную (набор текста) нередко возникают опечатки и ошибки, которые могут ухудшить качество перевода. Задача поиска и исправления опечаток в том числе связана с поиском неполных дубликатов, когда опечатка выступает причиной появления дубликата.</li>
    <li>    <b>Удаление мусора.</b> К мусору, который может повлиять на качество модели, относятся чрезмерно длинные предложения; сегменты на языке, отличном от целевого; сегменты, состоящие только из символов или цифр.</li>
    <li>    <b>Анонимизация</b>. В соответствии с законами о защите персональных данных, любая идентифицирующая информация должна быть удалена из корпуса. Здесь возникает задача поиска NER и их замены на заглушку.</li>
    <li>    <b>Устранение несоответствий.</b>  Несоответствия в параллельных корпусах могут возникать по ряду причин, например, с течением времени перевод того или иного термина может измениться, и в корпусе возникает два варианта перевода. В этом случае предыдущий недействительный более вариант перевода необходимо удалить либо изменить на актуальный. Это более сложная задача поиска коллокаций и кандидатов на их перевод.</li>
</ol></br></br>
    
Удаление из корпуса дубликатов является одним из важных шагов очистки данных, однако дубликатами могут выступать не только полностью идентичные единицы. В ряде ситуаций возникает необходимость удаления дубликатов по ряду критериев, таких как, например: </br>
    <li>	различия в датах</li>
    <li>	номера телефонов в разных форматах</li>
    <li>	наличие разных ссылок</li>
    <li>	разные значения полей</li>
    <li>	опечатки</li>
    <li>	лишние символы (лишние пробелы, мягкие переносы)</li>
</br>
Надо отметить, что этап удаления дубликатов является только одной из задач. Оставшиеся задачи будут рассмотрены на дальнейших этапах проекта. 
</br>

### Данные
В этом проекте данные в виде параллельных корпусов уже накоплены в формате .tmx, который является exchange-форматом так называемой памяти переводов — Translation Memory (TM). Это xml-нотация для представления параллельных корпусов (включая метаданные), которая имеет понятную структуру и которая доступна для анализа и парсинга. </br>

Такие корпуса накапливались годами в процессе перевода и имеют размерность от 10 000 до 60 000 сегментов, достаточную для тренировки специализированных моделей.

### Подход к разработке проекта
Разработка проекта включает в себя несколько этапов:
    <li> Изучить <a href="https://docs.python.org/3/library/xml.etree.elementtree.html#module-xml.etree.ElementTree">The ElementTree XML API</a> для парсинга xml.</li>
    <li> Изучить и проанализивать структуру xml tmx-файлов, понять, как обращаться к нужным узлам xml.</li>
    <li> Понять, как искать полные дубликаты. Сравнивать строки и находить сходство. Изучить модуль <a href="https://docs.python.org/3/library/difflib.html">difflib</a>, класс SequenceMatcher (поиск коэффициента сходства).</li>
    <li> Стоит ли использовать регулярные выражения для поиска "проблемных мест"?</li>
    <li> Отдельный вопрос - как искать потенциальные дубликаты, если в тексте опечатки или добавлены/удалены незначащие слова (артикли, предлоги). Изучить возможность использования <a href="https://abiword.github.io/enchant/">pyenchant</a> для автоматизации исправления опечаток. Метод <a href="https://pypi.org/project/gensim/">Gensim</a> для получения N ближайших слов (most_similar). Использование Word Embeddings и FastText как дополнение к другим методам для повышения качества исправления опечаток.</li>
    <li> Опционально - написать пользовательский интерфейс.</li>
    
### Ожидаемые сложности
<ol>
    <li> Могут возникнуть непредвиденные сложности с парсингом xml, в зависимости от сложности его структуры. </li>
    <li> Поскольку tmx-файлы содержат большие объемы данных, их обработка может занять много времени. Найти способы ускорить (БД SQL?)</li> 
</ol> </br>

#### Полезные ссылки
Сравнение хэшируемых объектов:</br>
    <li> <a href="https://andreyex.ru/programmirovanie/python/kak-ispolzovat-modul-difflib-v-python/">Пример использования библиотеки difflib</a> </br>
    <li> <a href="https://docs-python.ru/standart-library/modul-difflib-python/klass-sequencematcher-modulja-difflib/">Класс SequenceMatcher</a>
</br></br>
Подготовка данных для MT:</br>
    <li> <a href="https://essay.utwente.nl/58377/1/scriptie_B_Fournier.pdf">Preprocessing on bilingual data for Statistical Machine Translation</a>
    <li> <a href="https://machinelearningmastery.com/prepare-french-english-dataset-machine-translation/?__cf_chl_tk=vR4NJ3eSFD4TUepWOdAJM7nFMZKoRgndFssQ.4PUVIQ-1673704047-0-gaNycGzNB-U">How to Prepare a French-to-English Dataset for Machine Translation</a>
    <li> <a href="https://custom.mt/how-anonymization-works-in-machine-translation/">How Anonymization Works in Machine Translation</a>
</br></br>
Работа с опечатками:
</br>
    <li> <a href="https://habr.com/ru/company/singularis/blog/358664/">Исправление опечаток, взгляд сбоку</a></li></br></br>
Коллокации в параллельных корпусах:</br>
    <li> <a href="https://www.researchgate.net/publication/220535804_Extracting_collocations_and_their_translations_from_parallel_corpora/">Extracting collocations and their translations from parallel corpora</a></li>
    
